### 1. 小批量训练（Mini-batch Training）

小批量训练是指将训练数据分成多个小批量（mini-batch），每个小批量包含若干个样本，然后依次用这些小批量的数据进行模型参数更新。

**特点**：
- **折中方法**：结合了全量训练和在线训练的优点。
- **计算效率**：利用矩阵运算的优势，可以更高效地进行计算。
- **收敛稳定性**：相比在线训练，收敛更稳定；相比全量训练，更新频率更高，收敛速度更快。
- **内存需求**：相比全量训练，所需的内存较小，适用于大数据集。

### 2. 在线训练（Online Training）

在线训练（也称增量训练）是指模型逐步接收和处理数据流，并在每次接收到新的数据样本后立即进行参数更新。

**特点**：
- **实时更新**：每次接收到新数据后立即更新模型参数，适用于数据流环境和实时应用。
- **低内存需求**：只需存储当前样本，适合处理连续不断的大量数据。
- **适应性强**：能够在数据分布发生变化时快速调整模型。
- **收敛不稳定**：由于每次更新基于单个样本，梯度计算存在高方差，收敛路径可能不稳定。

### 3. 全量训练（Batch Training）

全量训练（也称批量训练）是指在每次参数更新时使用整个训练集来计算梯度。

**特点**：
- **高稳定性**：每次参数更新基于全量数据，梯度计算准确，收敛路径稳定。
- **计算昂贵**：每次参数更新都需要遍历整个数据集，计算量大，速度慢。
- **高内存需求**：需要将整个数据集加载到内存中，对于大数据集可能不适用。
- **收敛速度慢**：每次更新后都需要重新遍历整个数据集，导致收敛速度较慢。


### 依照不同的分类标准，训练方式可能有不同的分类。这里是希望大家了解小批量训练这样一种训练模式~